---
content_type: page
description: This section contains links to other versions of 6.231 taught elsewhere.
  The first is a 6-lecture short course on Approximate Dynamic Programming, taught
  by Professor Dimitri P. Bertsekas at Tsinghua University in Beijing, China on June
  2014. The second is a condensed, more research-oriented version of the course, given
  by Prof. Bertsekas in Summer 2012.
hide_download: true
hide_download_original: null
learning_resource_types:
- Lecture Videos
ocw_type: CourseSection
title: Related Video Lectures
uid: e0ea5281-28d8-a624-388d-a079ca1ce048
---

**Summer 2014**

These videos and lecture notes are from a 6-lecture, 12-hour short course on Approximate Dynamic Programming, taught by Professor Dimitri P. Bertsekas at Tsinghua University in Beijing, China in June 2014. They focus primarily on the advanced research-oriented issues of large scale infinite horizon dynamic programming, which corresponds to lectures 11-23 of the MIT 6.231 course.

The complete set of lecture notes are available here: {{% resource_link 36fc4cba-abe5-0444-6b51-adb8a68f5958 "Complete Slides (PDF - 1.6MB)" %}}, and are also divided by lecture below. Additional supporting material can be obtained on [Prof. Bertsekas' web site](http://web.mit.edu/dimitrib/www/publ.html).

**Note To OCW Users**: All videos are from [Shuvomoy Das Gupta](https://www.youtube.com/playlist?list=PLiCLbsFQNFAxOmVeqPhI5er1LGf2-L9I4) on Youtube and are not provided under our [Creative Commons License](/terms/#cc).

{{< tableopen >}}
{{< theadopen >}}
{{< tropen >}}
{{< thopen >}}
TOPICS
{{< thclose >}}
{{< thopen >}}
VIDEO LECTURES
{{< thclose >}}
{{< thopen >}}
LECTURE NOTES
{{< thclose >}}

{{< trclose >}}

{{< theadclose >}}
{{< tropen >}}
{{< tdopen rowspan="3" >}}


Introduction to Dynamic Programming (DP)

*   Approximate DP
*   Finite Horizon Problems
*   DP Algorithm for Finite Horizon Problems
*   Infinite Horizon Problems
*   Basic Theory of Discounted Infinite Horizon Problems


{{< tdclose >}}
{{< tdopen >}}


{{% resource_link de94cc52-da5f-55bf-3113-2419c9fa5da8 "Approximate Dynamic Programming, Lecture 1, Part 1" %}}


{{< tdclose >}}
{{< tdopen rowspan="3" >}}
{{% resource_link 0b7f5ea6-3f6e-aa9b-151f-fc8cd29f362a "Lecture 1 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link 063c1c76-54ae-ec2b-f527-793f63e8a65b "Approximate Dynamic Programming, Lecture 1, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link 621a4834-66ac-89f7-1e32-26bfe4f56f61 "Approximate Dynamic Programming, Lecture 1, Part 3" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen rowspan="3" >}}


Review of Discounted Problem Theory, Shorthand Notation

*   Algorithms for Discounted DP
*   Value Iteration (VI)
*   Policy Iteration (PI)
*   Q-Factors and Q-Learning
*   DP Models
*   Asynchronous Algorithms


{{< tdclose >}}
{{< tdopen >}}
{{% resource_link 389f739f-de18-25e9-530a-339198719cf2 "Approximate Dynamic Programming, Lecture 2, Part 1" %}}
{{< tdclose >}}
{{< tdopen rowspan="3" >}}
{{% resource_link 625f95b3-09b2-9ae5-f2c8-51f9eab1937c "Lecture 2 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link 952d7177-417a-b17a-7f03-1ee7de5ac20b "Approximate Dynamic Programming, Lecture 2, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link 288453cd-087c-33cb-9030-dd4e8f925c67 "Approximate Dynamic Programming, Lecture 2, Part 3" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen rowspan="2" >}}


General Issues of Approximation and Simulation for Large-Scale Problems

*   Introduction to Approximate DP
*   Approximation Architectures
*   Simulation-Based Approximate Policy Evaluation
*   General Issues Regarding Approximation and Simulation


{{< tdclose >}}
{{< tdopen >}}
{{% resource_link fba160f9-4c96-b583-9987-b0ded6fa4328 "Approximate Dynamic Programming, Lecture 3, Part 1" %}}
{{< tdclose >}}
{{< tdopen rowspan="2" >}}
{{% resource_link 153406d3-4238-5765-bd3c-b2c87d0256c6 "Lecture 3 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link 895d5205-a200-a4bc-b111-1a7677e1583f "Approximate Dynamic Programming, Lecture 3, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen rowspan="2" >}}


Approximate Policy Iteration based on Temporal Differences, Projected Equations, Galerkin Approximation

*   Approximation in Value Space
*   Approximate VI and PI
*   Projected Bellman Equations
*   Matrix Form of the Projected Equation
*   Simulation-Based Implementation
*   LSTD and LSPE Methods
*   Bias-Variance Tradeoff


{{< tdclose >}}
{{< tdopen >}}
{{% resource_link 59964273-cf0f-0cf5-1d27-6f4982298a0a "Approximate Dynamic Programming, Lecture 4, Part 1" %}}
{{< tdclose >}}
{{< tdopen rowspan="2" >}}
{{% resource_link 220247e6-07eb-3074-cfbb-977c0baa3c53 "Lecture 4 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link d80432ed-7961-1b32-a877-31f68d63a958 "Approximate Dynamic Programming, Lecture 4, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen rowspan="3" >}}


Aggregation Methods

*   Review of Approximate PI Based on Projected Bellman Equations
*   Issues of Policy Improvement
*   Exploration Enhancement in Policy Evaluation
*   Oscillations in Approximate PI
*   Aggregation: Examples, Simulation-Based, Relation with Projected Equations


{{< tdclose >}}
{{< tdopen >}}
{{% resource_link ae8a6239-2306-abf2-a2e5-a1e7f7aa70df "Approximate Dynamic Programming, Lecture 5, Part 1" %}}
{{< tdclose >}}
{{< tdopen rowspan="3" >}}
{{% resource_link d808bf6b-6f83-544f-f473-e148ef820b31 "Lecture 5 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link cb38cb7b-b267-4b52-6c43-245454701886 "Approximate Dynamic Programming, Lecture 5, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link e4670ce4-7236-f565-6b11-f4db11c4ec74 "Approximate Dynamic Programming, Lecture 5, Part 3" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen rowspan="2" >}}


Q-Learning, Approximation in Policy Space

*   Review of Q-Factors and Bellman Equations for Q-Factors
*   VI and PI for Q-Factors
*   Q-Learning: Combination of VI and Sampling
*   Q-Learning and Cost Function Approximation
*   Adaptive Dynamic Programming
*   Approximation in Policy Space
*   Additional Topics


{{< tdclose >}}
{{< tdopen >}}
{{% resource_link cd9e81ea-a5bc-fec3-c77f-4e3d6477507c "Approximate Dynamic Programming, Lecture 6, Part 1" %}}
{{< tdclose >}}
{{< tdopen rowspan="2" >}}
{{% resource_link 5bae5038-1da2-6cf6-6412-a548d743db30 "Lecture 6 (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
{{% resource_link cd0a2d00-b78b-a4b6-81c4-bc0b23408f2c "Approximate Dynamic Programming, Lecture 6, Part 2" %}}
{{< tdclose >}}

{{< trclose >}}

{{< tableclose >}}

**{{< anchor "2012" >}}{{< /anchor >}}Summer 2012**
---------------------------------------------------

These notes are from a condensed, more research-oriented version of the course, given by Prof. Bertsekas in Summer 2012.

{{% resource_link b78b16b8-c003-ed7b-4266-69ca44ff5dc0 "Short Course Notes (PDF)" %}}

{{< tableopen >}}
{{< theadopen >}}
{{< tropen >}}
{{< thopen >}}
LEC #
{{< thclose >}}
{{< thopen >}}
LECTURE NOTES
{{< thclose >}}

{{< trclose >}}

{{< theadclose >}}
{{< tropen >}}
{{< tdopen >}}
1
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link db48c4c6-88ca-3da7-8673-85939cbacf02 "Exact DP: Infinite Horizon Problems (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
2
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link bb07e677-5d7c-84ca-f39b-619ecdb340a2 "Exact DP: Large-scale Computational Methods (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
3
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link b20673a0-3092-38c4-22af-d4c37a417645 "General Issues of Approximation and Simulation (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
4
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link 924829f3-1656-bd1c-16c9-b4b1f8a984f6 "Temporal Differences (TD), Projected Equations, Galerkin Approximation (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
5
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link 573d6205-bfb1-b0b3-4e51-8e78eeba7f7d "Aggregation Methods (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
6
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link f6ceb6b9-cfb2-e79f-6ce4-863df79263b7 "Stochastic Approximation, Q-learning, and Other Methods (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}
{{< tropen >}}
{{< tdopen >}}
7
{{< tdclose >}}
{{< tdopen >}}
{{% resource_link 6fe55ff1-30be-e6ad-e877-466c130c0e29 "Monte Carlo Methods (PDF)" %}}
{{< tdclose >}}

{{< trclose >}}

{{< tableclose >}}